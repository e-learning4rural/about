Here is a more **website-friendly, concise, and visually scannable** version suitable for a landing page:

```markdown
## ğŸ“… Program Timeline

### ğŸš€ Phase 1 â€” Submission  
**May 6 â€“ July 6, 2026**

Teams submit:

- ğŸ¥ 5â€“7 minute video demonstration  
- ğŸ“„ Technical + ethical documentation  
- ğŸ§ª Functional prototype  
  (Web-based tool, lightweight executable, or guided simulation hosted on an open repository)

**Expected submissions:** 8â€“12 projects

---

### ğŸ” Phase 2 â€” Participatory Evaluation & Prototype Testing  
**July 7 â€“ July 28, 2026**

All projects undergo structured, community-informed evaluation.

#### ğŸ‘©â€ğŸ« Expert Educator Panel (5)
Educators from rural or under-resourced contexts evaluate:

- Feasibility  
- Pedagogical value  
- Cultural appropriateness  
- Ethical design  

#### ğŸŒ Remote Learner Panel (10)
Learners from marginalized communities participate in a 14-day guided testing period.

They assess:

- Usability  
- Accessibility in low-bandwidth settings  
- Cultural resonance  
- Relevance to lived learning needs  

Participation includes:
- 2â€“3 hours total engagement  
- Structured surveys  
- Facilitated feedback sessions  
- Fair compensation  
- Privacy and risk safeguards  

---

### ğŸ¤ Phase 3 â€” Live Online Showcase  
**August 15, 2026**

A four-hour public event featuring:

- Finalist presentations  
- Moderated Q&A  
- Reflections from educator and learner panelists  
- Community voting (non-determinative)  
- Awards ceremony  

---

## ğŸ† Competition Tracks

Both tracks use a shared ethical evaluation rubric.

### ğŸŒ± Track 1 â€” Real-World Impact
For solutions ready (or near-ready) for deployment in under-resourced contexts.

### ğŸ’¡ Track 2 â€” Innovation Track
For novel, experimental, or breakthrough approaches advancing ethical AI in remote learning.
```

If you'd like, I can also provide:

* A **minimalist version** (less text, more impact)
* A **more formal academic version**
* Or a **high-energy call-for-submissions version** designed to attract developers.


<details>
  <summary> Rubric Category: Usability & Accessibility </summary>

Example of the learner survey items:
- â€œI could use this tool without external help.â€ (1â€“5 scale)
- â€œThe tool worked well with limited internet.â€ (1â€“5 scale)
- â€œInstructions were clear.â€ (1â€“5 scale)
- â€œI would use this for my own learning.â€ (Yes/No + Why)

Educators receive then provide evaluation:
- Quantitative averages
- Thematic summary of qualitative responses
- Flagged issues (e.g., confusion, harm concerns)
- Score â€œUsability & Accessibilityâ€ informed by:
  - Their professional judgment
  - Learner experience data
 
</details> 
